{
 "cells": [
  {
   "cell_type": "raw",
   "id": "36bc7317-491a-4a81-86e9-e14ed67860f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "raw",
     "checksum": "e87c21354e836f5720814bc4fba7dd34",
     "grade": false,
     "grade_id": "cell-814dc5ea6e8d36c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "This  material,  no  matter  whether  in  printed  or  electronic  form, may  be  used  for  personal  and non-commercial educational use only.  \n",
    "Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa621f2-d135-41f1-b71c-5cdf85543e7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6d4f7d4d60fb8f3fbd74577e018e9ca",
     "grade": false,
     "grade_id": "cell-abb835e443dbde96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br><br>\n",
    "<span style=\"font-size:2em;font-weight:lighter;\">194.025 Introduction to Machine Learning</span><br>\n",
    "<span style=\"font-size:3em;font-weight:normal;line-height:70%;\">Assignment 5: How to grow and care for a Tree</span>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a56c2a-4499-4f4f-a6f2-c40ae341e33f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a42fe6e24611956293cafeb4dd720162",
     "grade": false,
     "grade_id": "cell-c99a8bffb61771c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to the 5th assignment of our course **Introduction to Machine Learning**. You will be able to earn up to a total of 10 points. Please read all descriptions carefully to get a full picture of what you have to do.\n",
    "\n",
    "**Remark:** Some code cells are put to read-only. Please execute them regardless as they contain important code. You can run a jupyter cell by pressing `SHIFT + ENTER`, or by pressing the play button on top (in the row where you can find the save button). Cells where you have to implement code contain the comment `# YOUR CODE HERE` followed by `raise NotImplementedError`. Simply remove the `raise NotImplementedError`and insert your code.\n",
    "\n",
    "Some other code cells start with the comment `# hidden tests ...`. Please do not change them in any way as they are used to grade the tasks after your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f57e14-8b45-48cf-b55a-0aca598cec82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47afa89da726d59d209614894e3f1649",
     "grade": false,
     "grade_id": "cell-efb02f123bd9e4c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment, you will implement important parts of a machine learning pipeline. We begin with implementing a weak baseline classifier. Then, we move on to implementing evaluation metrics that allow us to determine how good our classifier performs. Finally, we use cross-validation to investigate how our model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2ddac05-b592-4f69-b44d-14638f66f93d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92d7f0b618b20fd4748362734882f5d6",
     "grade": false,
     "grade_id": "cell-7e72f5caf20659b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seeds():\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf503a1-20b1-459f-82e5-9aab051ad167",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36aba5d20cb7f3b2f788e3a550da2ad6",
     "grade": false,
     "grade_id": "cell-27a6b84e6150aad9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Dummy Classifier (2 Points)\n",
    "\n",
    "We will start by implementing a **dummy classifier**. This classifier is intended to completely ignore the given datapoints and just predict the most common class in the training set.\n",
    "When casting `fit` on a training set `X, y` this classifier is supposed to determine the most common class _C_ in the training set. When calling `predict` this classifier will simply classify every example as class _C_. This classifier should be written such that it is compatible with the _sklearn_ ML framework, this also shows you how simple it is to add custom models to sklearn. For this, the class `DummyClassifier` inherits from `sklearn` classification classes and we only need to overwrite `fit` and `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c76bc8f1-2d96-427a-9f96-9d5719adfe01",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40240abb4d11b6ba152fce6a0a74c864",
     "grade": false,
     "grade_id": "cell-ef0844f78e72c8bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "from sklearn.base import BaseEstimator, ClassifierMixin\n\n\nclass DummyClassifier(BaseEstimator, ClassifierMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y):\n        \"\"\"\n        Fits the dummy classifier on the training set (X,y) i.e., extracts and stores the most common class\n\n        Parameters\n        ----------\n        X : array-like (numpy.ndarray with floats or ints) of shape (n_samples, n_features)\n           Meaning we have in X we have n_samples datapoints of dimension n_features and a corresponding class for each datapoint in y (e.g. y[1] is the class of datapoint X[1,:])\n        y : array-like (numpy.ndarray with ints) of shape (n_samples,)\n        \"\"\"\n        # YOUR CODE HERE\n        raise NotImplementedError()\n\n    def predict(self, X):\n        \"\"\"\n        Performs predictions based on the datapoints (X)\n        The classifier should output the most common class from the dataset\n\n        Parameters\n        ----------\n        X : array-like (numpy.ndarray with floats or ints) of shape (n_samples2, n_features2)\n\n        Returns\n        -------\n        y : array-like (numpy.ndarray with ints) of shape (n_samples2,)\n        \"\"\"\n        # YOUR CODE HERE\n        raise NotImplementedError()"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class DummyClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the dummy classifier on the training set (X,y) i.e., extracts and stores the most common class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like (numpy.ndarray with floats or ints) of shape (n_samples, n_features)\n",
    "           Meaning we have in X we have n_samples datapoints of dimension n_features and a corresponding class for each datapoint in y (e.g. y[1] is the class of datapoint X[1,:])\n",
    "        y : array-like (numpy.ndarray with ints) of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # Mean of y is between 0 and 1, if 1 is more common, it will get rounded to 1, otherwise 0\n",
    "        #n_samples = len(y)\n",
    "        #common_class = np.round(np.mean(y))\n",
    "\n",
    "        self.most_common_class_ = np.bincount(y).argmax()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Performs predictions based on the datapoints (X)\n",
    "        The classifier should output the most common class from the dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like (numpy.ndarray with floats or ints) of shape (n_samples2, n_features2)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like (numpy.ndarray with ints) of shape (n_samples2,)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "        # Predict the most common class for all inputs\n",
    "        y = np.full(X.shape[0], self.most_common_class_)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d61daf6c-3928-44b7-ab63-557f9a105b47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfa65e1c0662ecf141d2c569b0d6f777",
     "grade": true,
     "grade_id": "cell-952ac9e1f34e96be",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c12e2-8ff4-4e1a-830a-aeac53d10de3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8b3f0219c45e34eb3e356a665f4126b",
     "grade": false,
     "grade_id": "cell-c2129be68c065411",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Evaluation Metrics (3 Points)\n",
    "\n",
    "To evaluate how well our model performs we need a way to compute a metric that compares predictions `y_predict` against ground-truth `y_true`. For this you will implement two different classification metrics from the lecture: accuracy and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "672ab01c-9c3f-496a-b18d-a81ddb50b9d2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782949e7ccaa40ee1e856e73da1e470e",
     "grade": false,
     "grade_id": "cell-cf9d67fb60f2f01e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def accuracy(y_true, y_pred):\n    \"\"\"\n    Takes ground truth classes and predict classes and returns accuracy (see lecture).\n    You can assume that every class is either 0 or 1.\n\n    Expected output: float with accuracy.\n\n    Parameters\n    ----------\n    y_true : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n        Ground truth classes (i.e. the correct classes)\n    y_pred : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n        Predicted classes \n    \"\"\"\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n\ndef f1(y_true, y_pred):\n    \"\"\"\n    Takes ground truth classes and predict classes and returns the f1 score (see lecture).\n    You can assume that every class is either 0 or 1. Treat 1 as positive and 0 as negative.\n\n    Expected output: float with f1 score.\n\n    Parameters\n    ----------\n    y_true : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n        Ground truth classes (i.e. the correct classes)\n    y_pred : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n        Predicted classes \n    \"\"\"\n    # YOUR CODE HERE\n    raise NotImplementedError()"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Takes ground truth classes and predict classes and returns accuracy (see lecture).\n",
    "    You can assume that every class is either 0 or 1.\n",
    "\n",
    "    Expected output: float with accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n",
    "        Ground truth classes (i.e. the correct classes)\n",
    "    y_pred : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n",
    "        Predicted classes \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    n = len(y_true)\n",
    "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    true_negative = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    result: float = (true_positive + true_negative)/n\n",
    "    return result \n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Takes ground truth classes and predict classes and returns the f1 score (see lecture).\n",
    "    You can assume that every class is either 0 or 1. Treat 1 as positive and 0 as negative.\n",
    "\n",
    "    Expected output: float with f1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n",
    "        Ground truth classes (i.e. the correct classes)\n",
    "    y_pred : numpy.ndarray of integers with shape (n_samples,) all integers are either 0 or 1\n",
    "        Predicted classes \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    false_positive = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    false_negative = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if true_positive + false_positive == 0 or true_positive + false_negative == 0:\n",
    "        return 0.0  \n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "\n",
    "    result: float = 2 * precision * recall / (precision + recall)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f8ccc84-149c-45b3-a688-1a8ca4688a23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccf6666d356d68c5c066573427ee38c9",
     "grade": true,
     "grade_id": "cell-9e9989199de6e83e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aadcfdba-1e87-49ec-93ea-1f113a0a9282",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90110a10a19d067b79fbf9bc234833d3",
     "grade": true,
     "grade_id": "cell-ba5a7ec9677474ab",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14479e0c-eefb-4c23-b886-4e9e15de0189",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d51a9fc7cb62f1cc81bf973ae98899e",
     "grade": false,
     "grade_id": "cell-2e6aa9cc7ca6bfc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Accuracy vs F1 Score (2 Points)\n",
    "\n",
    "You have heard in the lecture that the accuracy can be misleading. This exercise is intended to strengthen your intuition of this problem, for this you will construct an example where this is the case.  More precisely, you must define predictions `y_pred` and groundtruths `y_true` such that the accuracy is at least 0.95 and the F1 score is at most 0.6. Both predictions and ground truths should have the shape of a numpy array with 0 and 1 as entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47e47f65-aa8a-45fa-9f4d-8543c810806a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a35cf6300b29e1b32cd75488f95e26ff",
     "grade": false,
     "grade_id": "cell-0f5f6bd2bd9e2d29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "# Enter arrays below\ny_true = np.array([0,1], dtype=int)\ny_pred = np.array([0,1], dtype=int)\n\n# YOUR CODE HERE\nraise NotImplementedError()\n\nprint(f\"Accuracy: {accuracy(y_true, y_pred)}\")\nprint(f\"F1 Score: {f1(y_true, y_pred)}\")"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Enter arrays below\n",
    "y_true = np.array([0,1], dtype=int)\n",
    "y_pred = np.array([0,1], dtype=int)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# F1 Score: Harmonic mean of precision and recall. It punishes classifiers that have very unbalanced precision and recall.\n",
    "# It reveals the failure of the classifier to detect the positive class at all.\n",
    "y_true = np.array([0]*95 + [1]*5, dtype=int)\n",
    "y_pred = np.array([0]*100, dtype=int)\n",
    "\n",
    "print(f\"Accuracy: {accuracy(y_true, y_pred)}\")\n",
    "print(f\"F1 Score: {f1(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "448323a3-f245-4b81-a3ee-e9bcb8505b19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29c119701f181bfb3081461722b1cc9f",
     "grade": true,
     "grade_id": "cell-63cf57112648cb9a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa61751-6e36-424a-97d2-fb1613b6fead",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c02fa07959d11ba727970a54d0718aef",
     "grade": false,
     "grade_id": "cell-c75a3bbc8c7aef5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Cross Validating (3 Points)\n",
    "\n",
    "In the lecture you have seen how to split your dataset using the holdout method. Here, we will use 4-fold _cross validation_ to evaluate our dummy classifier on different splits of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d6e4b04-080a-488b-b4cd-760e5927e41e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac05480ded5b820efc0d3776dba54ab4",
     "grade": false,
     "grade_id": "cell-b11c55eff0b85a76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "X = np.random.random((10000, 10))\n",
    "y = np.random.randint(low=0, high=5, size=(10000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6484cb62-0a7e-45bb-ae9c-6c09560f3db6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a63c018e9e36959273e84965a7527e4",
     "grade": false,
     "grade_id": "cell-b91289b5c335b2f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### 1. Split your data\n",
    "_sklearn_ provides you with a method to get a cross-validation split for the dataset with [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). Use this to split the training set (X,y) such that\n",
    "- It gets split into 4 folds (i.e. 4-fold cross validation)\n",
    "- Do **not** set `shuffle` to `True` (this allows us to reproduce your solution)\n",
    "\n",
    "\n",
    "##### 2. Evaluate your model on each split \n",
    "For every $i$  from $\\{1,2,3,4 \\}$ select fold $i$ as test set and the remaining folds as training set. Train your dummy classifier on the training set and evaluate it on the test set. Collect the prediction accuracy on each split in an array called `accuracy_per_split`. \n",
    "In the end `accuracy_per_split` should contain 4 different floating numbers. Note that since `y` is generated by uniform distribution the average accuracy should be roughly 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51d3f715-83eb-4df8-9cb7-e262be6d4442",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa68167c7f972a1e7b377d5c208380f7",
     "grade": false,
     "grade_id": "cell-98332dcfc82c7500",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "accuracy_per_split = []\n\n# YOUR CODE HERE\nraise NotImplementedError()\n\nprint(f\"Average accuracy is {sum(accuracy_per_split)/len(accuracy_per_split):.2f}\")"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is 0.21\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_split = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    dc = DummyClassifier()\n",
    "    dc.fit(X_train, y_train)\n",
    "    y_pred = dc.predict(X_test)\n",
    "\n",
    "    acc = np.mean(y_pred == y_test)  # simple accuracy\n",
    "    accuracy_per_split.append(acc)\n",
    "\n",
    "print(f\"Average accuracy is {sum(accuracy_per_split)/len(accuracy_per_split):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0cfc7099-68cf-4593-a3d3-f294fb3a5a8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93c63516ff6306922cd17f4289131b70",
     "grade": true,
     "grade_id": "cell-92b7e300388dc834",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
